{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#from prepare import basic_clean, tokenize, stem, lemmatize, remove_stopwords, prep_article_data, words\n",
    "from acquire import scrape_github_data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Decision Tree and Random Forest ;D\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 250)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data.json')\n",
    "\n",
    "df = words(df)\n",
    "\n",
    "#df.info()\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 1) (120, 1) (100, 1)\n",
      "(280, 1) (120, 1) (100, 1)\n",
      "(280, 1) (120, 1) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Make copies of df with prepared columns and target\n",
    "clean_df = df.copy()[['language', 'clean']]\n",
    "stem_df = df.copy()[['language', 'stemmed']]\n",
    "lem_df = df.copy()[['language', 'lemmatized']]\n",
    "\n",
    "\n",
    "# Get splits for each of the above dfs and isolate target\n",
    "X_clean = clean_df[['clean']]\n",
    "y_clean = clean_df.language\n",
    "\n",
    "X_clean_train, X_clean_test, y_clean_train, y_clean_test = train_test_split(X_clean, y_clean, test_size=.2, random_state=302)\n",
    "X_clean_train, X_clean_validate, y_clean_train, y_clean_validate  = train_test_split(X_clean_train, y_clean_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_clean_train.shape, X_clean_validate.shape, X_clean_test.shape)\n",
    "\n",
    "X_stem = stem_df[['stemmed']]\n",
    "y_stem = stem_df.language\n",
    "\n",
    "X_stem_train, X_stem_test, y_stem_train, y_stem_test = train_test_split(X_stem, y_stem, test_size=.2, random_state=302)\n",
    "X_stem_train, X_stem_validate, y_stem_train, y_stem_validate  = train_test_split(X_stem_train, y_stem_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_stem_train.shape, X_stem_validate.shape, X_stem_test.shape)\n",
    "\n",
    "X_lem = lem_df[['lemmatized']]\n",
    "y_lem = lem_df.language\n",
    "\n",
    "X_lem_train, X_lem_test, y_lem_train, y_lem_test = train_test_split(X_lem, y_lem, test_size=.2, random_state=302)\n",
    "X_lem_train, X_lem_validate, y_lem_train, y_lem_validate  = train_test_split(X_lem_train, y_lem_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_lem_train.shape, X_lem_validate.shape, X_lem_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make vectorizer objects for bags of words (clean_df)\n",
    "cv_clean = CountVectorizer()\n",
    "tfidf_clean = TfidfVectorizer()\n",
    "\n",
    "#Bags of words\n",
    "cv_clean_bow = cv_clean.fit_transform(X_clean_train.clean)\n",
    "tf_clean_bow = tfidf_clean.fit_transform(X_clean_train.clean)\n",
    "\n",
    "# Make and fit decision tree object for cv_clean_bow\n",
    "cv_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree1.fit(cv_clean_bow, y_clean_train)\n",
    "\n",
    "# #Output tree score\n",
    "# print(f'CV tree 1 score: {cv_tree1.score(cv_clean_bow, y_clean_train)}')\n",
    "\n",
    "# #Make and fit decision tree object for tf_clean_bow\n",
    "# tf_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "# tf_tree1.fit(tf_clean_bow, y_clean_train)\n",
    "\n",
    "#Output tree score\n",
    "#print(f'TF/IDF tree 1 score: {tf_tree1.score(tf_clean_bow, y_clean_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 2 score: 0.8571428571428571\n",
      "TF IDF tree 2 score: 0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "# # \"Stemmed\" models\n",
    "# cv_stem = CountVectorizer()\n",
    "# tfidf_stem = TfidfVectorizer()\n",
    "\n",
    "# # Bags\n",
    "# cv_stem_bow = cv_stem.fit_transform(X_stem_train.stemmed)\n",
    "# tf_stem_bow = tfidf_stem.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# # Make and fit decision tree object for cv_stem_bow\n",
    "# cv_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "# cv_tree2.fit(cv_stem_bow, y_stem_train)\n",
    "\n",
    "# #Output tree score\n",
    "# print(f'CV tree 2 score: {cv_tree2.score(cv_stem_bow, y_stem_train)}')\n",
    "\n",
    "# #Make and fit decision tree object for tf_stem_bow\n",
    "# tf_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "# tf_tree2.fit(tf_stem_bow, y_stem_train)\n",
    "\n",
    "# #Output tree score\n",
    "# print(f'TF IDF tree 2 score: {tf_tree2.score(tf_stem_bow, y_stem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 3 score: 0.8571428571428571\n",
      "TFIDF tree 3 score: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "# # \"Lemmatized\" models\n",
    "# cv_lem = CountVectorizer()\n",
    "# tfidf_lem = TfidfVectorizer()\n",
    "\n",
    "# cv_lem_bow = cv_lem.fit_transform(X_lem_train.lemmatized)\n",
    "# tf_lem_bow = tfidf_lem.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# # Make and fit decision tree object for cv_lem_bow\n",
    "# cv_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "# cv_tree3.fit(cv_lem_bow, y_lem_train)\n",
    "\n",
    "# #Make and fit decision tree object for tf_lem_bow\n",
    "# tf_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "# tf_tree3.fit(tf_lem_bow, y_lem_train)\n",
    "\n",
    "# Output tree scores\n",
    "print(f'CV tree 3 score: {cv_tree3.score(cv_lem_bow, y_lem_train)}') \n",
    "print(f'TFIDF tree 3 score: {tf_tree3.score(tf_lem_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classi_bow(X_lem_train,y_lem_train,X_stem_train,y_stem_train,X_clean_train,y_clean_train):\n",
    "\n",
    "    # Make vectorizer objects for bags of words (clean_df)\n",
    "    cv_clean = CountVectorizer()\n",
    "    tfidf_clean = TfidfVectorizer()\n",
    "\n",
    "    #Bags of words\n",
    "    cv_clean_bow = cv_clean.fit_transform(X_clean_train[['clean']].clean)\n",
    "    tf_clean_bow = tfidf_clean.fit_transform(X_clean_train[['clean']].clean)\n",
    "    \n",
    "    # Make and fit decision tree object for cv_clean_bow\n",
    "    cv_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "    cv_tree1.fit(cv_clean_bow, y_clean_train)\n",
    "\n",
    "    #Make and fit decision tree object for tf_clean_bow\n",
    "    tf_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "    tf_tree1.fit(tf_clean_bow, y_clean_train)\n",
    "\n",
    "\n",
    "    # \"Stemmed\" models\n",
    "    cv_stem = CountVectorizer()\n",
    "    tfidf_stem = TfidfVectorizer()\n",
    "\n",
    "    # Bags\n",
    "    cv_stem_bow = cv_stem.fit_transform(X_stem_train[['stemmed']].stemmed)\n",
    "    tf_stem_bow = tfidf_stem.fit_transform(X_stem_train[['stemmed']].stemmed)\n",
    "\n",
    "    # Make and fit decision tree object for cv_stem_bow\n",
    "    cv_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "    cv_tree2.fit(cv_stem_bow, y_stem_train)\n",
    "\n",
    "    # Make and fit decision tree object for tf_stem_bow\n",
    "    tf_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "    tf_tree2.fit(tf_stem_bow, y_stem_train)\n",
    "\n",
    "\n",
    "    # \"Lemmatized\" models\n",
    "    cv_lem = CountVectorizer()\n",
    "    tfidf_lem = TfidfVectorizer()\n",
    "\n",
    "    # Bags\n",
    "    cv_lem_bow = cv_lem.fit_transform(X_lem_train[['lemmatized']].lemmatized)\n",
    "    tf_lem_bow = tfidf_lem.fit_transform(X_lem_train[['lemmatized']].lemmatized)\n",
    "\n",
    "    # Make and fit decision tree object for cv_lem_bow\n",
    "    cv_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "    cv_tree3.fit(cv_lem_bow, y_lem_train)\n",
    "\n",
    "    #Make and fit decision tree object for tf_lem_bow\n",
    "    tf_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "    tf_tree3.fit(tf_lem_bow, y_lem_train)\n",
    "\n",
    "\n",
    "    dec_tree_training_scores=pd.Series({\n",
    "        'CV_clean': cv_tree1.score(cv_clean_bow, y_clean_train),\n",
    "        'CV_stem': cv_tree2.score(cv_stem_bow, y_stem_train),\n",
    "        'CV_lem': cv_tree3.score(cv_lem_bow, y_lem_train),\n",
    "        'TFIDF_clean': tf_tree1.score(tf_clean_bow, y_clean_train),\n",
    "        'TFIDF_stem': tf_tree2.score(tf_stem_bow, y_stem_train),\n",
    "        'TFIDF_lem': tf_tree3.score(tf_lem_bow, y_lem_train)\n",
    "    })\n",
    "\n",
    "    return dec_tree_training_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_training_scores=classi_bow(X_lem_train,y_lem_train,X_stem_train,y_stem_train,X_clean_train,y_clean_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV_clean       0.825000\n",
       "CV_stem        0.817857\n",
       "CV_lem         0.821429\n",
       "TFIDF_clean    0.842857\n",
       "TFIDF_stem     0.850000\n",
       "TFIDF_lem      0.839286\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_training_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training split model evaluation: TF IDF vectorizers outscore count vectorizers. Lemmatized text preparation yields highest score on trees using TF IDF vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_clean_bow_val = tfidf_clean.transform(X_clean_validate.clean)\n",
    "\n",
    "#Get tf_tree1 score on validate\n",
    "#tf_tree1.score(tf_clean_bow_val, y_clean_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerable drop off. Probably overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_stem_bow_val = tfidf_stem.transform(X_stem_validate.stemmed)\n",
    "\n",
    "#Get tf_tree1 score on validate\n",
    "#tf_tree2.score(tf_stem_bow_val, y_stem_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even worse dropoff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5416666666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform validate split with vectorizer\n",
    "tf_lem_bow_val = tfidf_lem.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "#Get tf_tree1 score on validate\n",
    "#tf_tree3.score(tf_lem_bow_val, y_lem_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significant dropoff for each text preparation. Cleaned preparation scored 62.5% and will be tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest models, 100 estimators, max depth 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RF 1 score: 0.8071428571428572\n",
      "TF/IDF RF 1 score: 0.85\n",
      "CV RF 2 score: 0.8285714285714286\n",
      "TF/IDF RF 2 score: 0.8785714285714286\n",
      "CV RF 3 score: 0.8035714285714286\n",
      "TF/IDF RF 3 score: 0.8535714285714285\n"
     ]
    }
   ],
   "source": [
    "# Make vectorizer objects\n",
    "cv_clean2 = CountVectorizer()\n",
    "tfidf_clean2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_clean2_bow = cv_clean2.fit_transform(X_clean_train.clean)\n",
    "tf_clean2_bow = tfidf_clean2.fit_transform(X_clean_train.clean)\n",
    "\n",
    "# Make and fit decision tree object for cv_clean2_bow\n",
    "cv_rf1 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf1.fit(cv_clean2_bow, y_clean_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_clean2_bow\n",
    "tf_rf1 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf1.fit(tf_clean2_bow, y_clean_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 1 score: {cv_rf1.score(cv_clean2_bow, y_clean_train)}')\n",
    "print(f'TF/IDF RF 1 score: {tf_rf1.score(tf_clean2_bow, y_clean_train)}')\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_stem2 = CountVectorizer()\n",
    "tfidf_stem2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_stem2_bow = cv_stem2.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem2_bow = tfidf_stem2.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit decision tree object for cv_stem2_bow\n",
    "cv_rf2 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf2.fit(cv_stem2_bow, y_stem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_stem2_bow\n",
    "tf_rf2 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf2.fit(tf_stem2_bow, y_stem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 2 score: {cv_rf2.score(cv_stem2_bow, y_stem_train)}')\n",
    "print(f'TF/IDF RF 2 score: {tf_rf2.score(tf_stem2_bow, y_stem_train)}')\n",
    "# Make vectorizer objects\n",
    "cv_lem2 = CountVectorizer()\n",
    "tfidf_lem2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_lem2_bow = cv_lem2.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem2_bow = tfidf_lem2.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit decision tree object for cv_lem2_bow\n",
    "cv_rf3 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf3.fit(cv_lem2_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_lem2_bow\n",
    "tf_rf3 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf3.fit(tf_lem2_bow, y_lem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 3 score: {cv_rf3.score(cv_lem2_bow, y_lem_train)}')\n",
    "print(f'TF/IDF RF 3 score: {tf_rf3.score(tf_lem2_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both vectorizers scoring the same on training split for all text preparations. All move on to validate.\n",
    "\n",
    "### Update (16-May-2022): TF/IDF vectorizers scoring higher on increased dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF/IDF RF 3 score on validate: 0.675\n",
      "TF/IDF RF 3 score on validate: 0.6916666666666667\n",
      "TF/IDF RF 3 score on validate: 0.675\n"
     ]
    }
   ],
   "source": [
    "# Transform count vectorizers on validate\n",
    "#cv_clean2_bow_val = cv_clean2.transform(X_clean_validate.clean)\n",
    "#cv_stem2_bow_val = cv_stem2.transform(X_stem_validate.stemmed)\n",
    "#cv_lem2_bow_val = cv_lem2.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Output CV RF scores\n",
    "#print(f'CV RF 1 score on validate: {cv_rf1.score(cv_clean2_bow_val, y_clean_validate)}')\n",
    "#print(f'CV RF 2 score on validate: {cv_rf2.score(cv_stem2_bow_val, y_stem_validate)}')\n",
    "#print(f'CV RF 3 score on validate: {cv_rf3.score(cv_lem2_bow_val, y_lem_validate)}')\n",
    "\n",
    "# Transform TF IDF vectorizers on validate\n",
    "tf_clean2_bow_val = tfidf_clean2.transform(X_clean_validate.clean)\n",
    "tf_stem2_bow_val = tfidf_stem2.transform(X_stem_validate.stemmed)\n",
    "tf_lem2_bow_val = tfidf_lem2.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Output TF IDF RF scores\n",
    "print(f'TF/IDF RF 3 score on validate: {tf_rf1.score(tf_clean2_bow_val, y_clean_validate)}')\n",
    "print(f'TF/IDF RF 3 score on validate: {tf_rf2.score(tf_stem2_bow_val, y_stem_validate)}')\n",
    "print(f'TF/IDF RF 3 score on validate: {tf_rf3.score(tf_lem2_bow_val, y_lem_validate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatized text prep for both vectorizers score highest, but TF/IDF outscores CV. Significant drop off for both vectorizers on all text preparations, though. \n",
    "\n",
    "### Update (16-May-2022): TF/IDF vectorizer on stemmed text scores highest at 69.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes modeling, alpha 0.5\n",
    "\n",
    "### Hold off on running the below cell on increased dataset for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV NB 1 score: 0.5357142857142857\n",
      "TF IDF NB 1 score: 0.5357142857142857\n",
      "CV NB 2 score: 0.5357142857142857\n",
      "TF IDF NB 2 score: 0.5357142857142857\n",
      "CV NB 3 score: 0.5357142857142857\n",
      "TF IDF NB 3 score: 0.5357142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_clean3 = CountVectorizer()\n",
    "tfidf_clean3 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_clean3_bow = cv_clean3.fit_transform(X_clean_train.clean)\n",
    "tf_clean3_bow = tfidf_clean3.fit_transform(X_clean_train.clean)\n",
    "\n",
    "# Make and fit Naive Bayes object for cv_clean3_bow\n",
    "cv_nb1 = CategoricalNB(alpha=0.5, min_categories=cv_clean3_bow.toarray().shape[1]) # min_categories kwarg to ensure model is fed a consistent number of categories\n",
    "cv_nb1.fit(cv_clean3_bow.toarray(), y_clean_train) # Naive Bayes requires dense data\n",
    "\n",
    "#Make and fit Naive Bayes object for tf_clean3_bow\n",
    "tf_nb1 = CategoricalNB(alpha=0.5, min_categories=cv_clean3_bow.toarray().shape[1])\n",
    "tf_nb1.fit(tf_clean3_bow.toarray(), y_clean_train) \n",
    "\n",
    "#Output NB scores\n",
    "print(f'CV NB 1 score: {cv_nb1.score(cv_clean3_bow.toarray(), y_clean_train)}')\n",
    "print(f'TF IDF NB 1 score: {tf_nb1.score(tf_clean3_bow.toarray(), y_clean_train)}')\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_stem3 = CountVectorizer()\n",
    "tfidf_stem3 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_stem3_bow = cv_stem3.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem3_bow = tfidf_stem3.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit Naive Bayes object for cv_stem3_bow\n",
    "cv_nb2 = CategoricalNB(alpha=0.5, min_categories=cv_stem3_bow.toarray().shape[1])\n",
    "cv_nb2.fit(cv_stem3_bow.toarray(), y_stem_train)\n",
    "\n",
    "#Make and fit Naive Bayes object for tf_stem3_bow\n",
    "tf_nb2 = CategoricalNB(alpha=0.5, min_categories=cv_stem3_bow.toarray().shape[1])\n",
    "tf_nb2.fit(tf_stem3_bow.toarray(), y_stem_train)\n",
    "\n",
    "#Output NB scores\n",
    "print(f'CV NB 2 score: {cv_nb2.score(cv_stem3_bow.toarray(), y_stem_train)}')\n",
    "print(f'TF IDF NB 2 score: {tf_nb2.score(tf_stem3_bow.toarray(), y_stem_train)}')\n",
    "# Make vectorizer objects\n",
    "cv_lem3 = CountVectorizer()\n",
    "tfidf_lem3 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_lem3_bow = cv_lem3.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem3_bow = tfidf_lem3.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit Naive Bayes object for cv_lem3_bow\n",
    "cv_nb3 = CategoricalNB(alpha=0.5, min_categories=cv_lem3_bow.toarray().shape[1])\n",
    "cv_nb3.fit(cv_lem3_bow.toarray(), y_lem_train)\n",
    "\n",
    "#Make and fit Naive Bayes object for tf_lem3_bow\n",
    "tf_nb3 = CategoricalNB(alpha=0.5, min_categories=cv_lem3_bow.toarray().shape[1])\n",
    "tf_nb3.fit(tf_lem3_bow.toarray(), y_lem_train)\n",
    "\n",
    "#Output NB scores\n",
    "print(f'CV NB 3 score: {cv_nb3.score(cv_lem3_bow.toarray(), y_lem_train)}')\n",
    "print(f'TF IDF NB 3 score: {tf_nb3.score(tf_lem3_bow.toarray(), y_lem_train)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes models score significantly lower than DT and RF on training data. Equal scores across text preparations and vectorizers.\n",
    "\n",
    "### Hold off on running the below cell on increased dataset for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV NB 1 score on validate: 0.5833333333333334\n",
      "CV NB 2 score on validate: 0.5833333333333334\n",
      "CV NB 3 score on validate: 0.5833333333333334\n",
      "TF/IDF NB 1 score on validate: 0.5833333333333334\n",
      "TF/IDF NB 2 score on validate: 0.5833333333333334\n",
      "TF/IDF NB 3 score on validate: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "# Transform count vectorizers on validate\n",
    "cv_clean3_bow_val = cv_clean3.transform(X_clean_validate.clean)\n",
    "cv_stem3_bow_val = cv_stem3.transform(X_stem_validate.stemmed)\n",
    "cv_lem3_bow_val = cv_lem3.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "tf_clean3_bow_val = tfidf_clean3.transform(X_clean_validate.clean)\n",
    "tf_stem3_bow_val = tfidf_stem3.transform(X_stem_validate.stemmed)\n",
    "tf_lem3_bow_val = tfidf_lem3.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Output CV NB scores\n",
    "print(f'CV NB 1 score on validate: {cv_nb1.score(cv_clean3_bow_val.toarray(), y_clean_validate)}')\n",
    "print(f'CV NB 2 score on validate: {cv_nb2.score(cv_stem3_bow_val.toarray(), y_stem_validate)}')\n",
    "print(f'CV NB 3 score on validate: {cv_nb3.score(cv_lem3_bow_val.toarray(), y_lem_validate)}')\n",
    "\n",
    "# Output TF/IDF NB scores\n",
    "print(f'TF/IDF NB 1 score on validate: {tf_nb1.score(tf_clean3_bow_val.toarray(), y_clean_validate)}')\n",
    "print(f'TF/IDF NB 2 score on validate: {tf_nb2.score(tf_stem3_bow_val.toarray(), y_stem_validate)}')\n",
    "print(f'TF/IDF NB 3 score on validate: {tf_nb3.score(tf_lem3_bow_val.toarray(), y_lem_validate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental improvement. Scores still even across all text preparations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bags of bigrams -- Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 4 score: 0.7214285714285714\n",
      "TF/IDF tree 4 score: 0.7214285714285714\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make bags for bigrams\n",
    "cv_clean4 = CountVectorizer(ngram_range=(2,2))\n",
    "tfidf_clean4 = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Fill bags with words\n",
    "cv_clean4_bow = cv_clean4.fit_transform(X_clean_train.clean)\n",
    "tf_clean4_bow = tfidf_clean4.fit_transform(X_clean_train.clean)\n",
    "\n",
    "\n",
    "# Make and fit decision tree object for cv_clean4_bow\n",
    "cv_tree4 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree4.fit(cv_clean4_bow, y_clean_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_clean_bow\n",
    "tf_tree4 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree4.fit(tf_clean4_bow, y_clean_train)\n",
    "\n",
    "#Output tree scores\n",
    "print(f'CV tree 4 score: {cv_tree4.score(cv_clean4_bow, y_clean_train)}')\n",
    "print(f'TF/IDF tree 4 score: {tf_tree4.score(tf_clean4_bow, y_clean_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 5 score: 0.725\n",
      "TF/IDF tree 5 score: 0.7285714285714285\n"
     ]
    }
   ],
   "source": [
    "#Make bags\n",
    "cv_stem4 = CountVectorizer(ngram_range=(2,2))\n",
    "tfidf_stem4 = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Fill bags with words\n",
    "cv_stem4_bow = cv_stem4.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem4_bow = tfidf_stem4.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "\n",
    "# Make and fit decision tree object for cv_stem4_bow\n",
    "cv_tree5 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree5.fit(cv_stem4_bow, y_stem_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_stem_bow\n",
    "tf_tree5 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree5.fit(tf_stem4_bow, y_stem_train)\n",
    "\n",
    "#Output tree scores\n",
    "print(f'CV tree 5 score: {cv_tree5.score(cv_stem4_bow, y_stem_train)}')\n",
    "print(f'TF/IDF tree 5 score: {tf_tree5.score(tf_stem4_bow, y_stem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 6 score: 0.7214285714285714\n",
      "TF/IDF tree 6 score: 0.725\n"
     ]
    }
   ],
   "source": [
    "# Make bags\n",
    "cv_lem4 = CountVectorizer(ngram_range=(2,2))\n",
    "tfidf_lem4 = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Fill bags with words\n",
    "cv_lem4_bow = cv_lem4.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem4_bow = tfidf_lem4.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "\n",
    "# Make and fit decision tree object for cv_lem4_bow\n",
    "cv_tree6 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree6.fit(cv_lem4_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_lem_bow\n",
    "tf_tree6 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree6.fit(tf_lem4_bow, y_lem_train)\n",
    "\n",
    "#Output tree scores\n",
    "print(f'CV tree 6 score: {cv_tree6.score(cv_lem4_bow, y_lem_train)}')\n",
    "print(f'TF/IDF tree 6 score: {tf_tree6.score(tf_lem4_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF/IDF vectorizers on stemmed and lemmatized text outperform count vectorizers by a thin margin. Both vectorizer scored the same on clean text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF/IDF [Bigram bags] Decision Tree scores on validate split:\n",
      "------------------------------------------------------------\n",
      "Tree 4 [clean] score: 0.7666666666666667\n",
      "Tree 5 [stemmed] score: 0.7583333333333333\n",
      "Tree 6 [lemmatized] score: 0.7416666666666667\n"
     ]
    }
   ],
   "source": [
    "print('TF/IDF [Bigram bags] Decision Tree scores on validate split:')\n",
    "print('------------------------------------------------------------')\n",
    "#Transform validate split with vectorizer\n",
    "tf_clean4_bow_val = tfidf_clean4.transform(X_clean_validate.clean)\n",
    "\n",
    "#Output tf_tree4 score on validate\n",
    "print(f'Tree 4 [clean] score: {tf_tree4.score(tf_clean4_bow_val, y_clean_validate)}')\n",
    "\n",
    "#Transform validate split with vectorizer\n",
    "tf_stem4_bow_val = tfidf_stem4.transform(X_stem_validate.stemmed)\n",
    "\n",
    "#Output tf_tree5 score on validate\n",
    "print(f'Tree 5 [stemmed] score: {tf_tree5.score(tf_stem4_bow_val, y_stem_validate)}')\n",
    "\n",
    "#Transform validate split with vectorizer\n",
    "tf_lem4_bow_val = tfidf_lem4.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "#Output tf_tree6 score on validate\n",
    "print(f'Tree 6 [lemmatized] score: {tf_tree6.score(tf_lem4_bow_val, y_lem_validate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RF 4 score: 0.5892857142857143\n",
      "TF IDF RF 4 score: 0.5714285714285714\n",
      "CV RF 5 score: 0.8392857142857143\n",
      "TF IDF RF 5 score: 0.8714285714285714\n",
      "CV RF 6 score: 0.7928571428571428\n",
      "TF IDF RF 6 score: 0.8642857142857143\n"
     ]
    }
   ],
   "source": [
    "# Make vectorizer objects\n",
    "cv_clean5 = CountVectorizer(ngram_range=(2,2))\n",
    "tfidf_clean5 = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_clean5_bow = cv_clean5.fit_transform(X_clean_train.clean)\n",
    "tf_clean5_bow = tfidf_clean5.fit_transform(X_clean_train.clean)\n",
    "\n",
    "# Make and fit random forest object for cv_clean5_bow\n",
    "cv_rf4 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf4.fit(cv_clean5_bow, y_clean_train)\n",
    "\n",
    "#Make and fit random forest object for tf_clean5_bow\n",
    "tf_rf4 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf4.fit(tf_clean5_bow, y_clean_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 4 score: {cv_rf4.score(cv_clean5_bow, y_clean_train)}')\n",
    "print(f'TF IDF RF 4 score: {tf_rf4.score(tf_clean5_bow, y_clean_train)}')\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_stem5 = CountVectorizer()\n",
    "tfidf_stem5 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_stem5_bow = cv_stem5.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem5_bow = tfidf_stem5.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit random object for cv_stem5_bow\n",
    "cv_rf5 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf5.fit(cv_stem5_bow, y_stem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_stem5_bow\n",
    "tf_rf5 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf5.fit(tf_stem5_bow, y_stem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 5 score: {cv_rf5.score(cv_stem5_bow, y_stem_train)}')\n",
    "print(f'TF IDF RF 5 score: {tf_rf5.score(tf_stem5_bow, y_stem_train)}')\n",
    "# Make vectorizer objects\n",
    "cv_lem5 = CountVectorizer()\n",
    "tfidf_lem5 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_lem5_bow = cv_lem5.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem5_bow = tfidf_lem5.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit decision tree object for cv_lem5_bow\n",
    "cv_rf6 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf6.fit(cv_lem5_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_lem5_bow\n",
    "tf_rf6 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf6.fit(tf_lem5_bow, y_lem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 6 score: {cv_rf6.score(cv_lem5_bow, y_lem_train)}')\n",
    "print(f'TF IDF RF 6 score: {tf_rf6.score(tf_lem5_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF/IDF vectorizers outperform count vectorizers overall. RFs on stemmed bigrams scoring highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RF 5 score on validate: 0.6833333333333333\n",
      "CV RF 6 score on validate: 0.6833333333333333\n",
      "TF/IDF RF 5 score on validate: 0.6666666666666666\n",
      "TF/IDF RF 6 score on validate: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Transform count vectorizers on validate\n",
    "cv_stem5_bow_val = cv_stem5.transform(X_stem_validate.stemmed)\n",
    "cv_lem5_bow_val = cv_lem5.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Transform TF/IDF vectorizers on validate\n",
    "tf_stem5_bow_val = tfidf_stem5.transform(X_stem_validate.stemmed)\n",
    "tf_lem5_bow_val = tfidf_lem5.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "#Output CV RF 5 & 6 scores on validate\n",
    "print(f'CV RF 5 score on validate: {cv_rf5.score(cv_stem5_bow_val, y_stem_validate)}')\n",
    "print(f'CV RF 6 score on validate: {cv_rf6.score(cv_lem5_bow_val, y_lem_validate)}')\n",
    "\n",
    "# Output TF/IDF RF 5 & 6 scores on validate\n",
    "print(f'TF/IDF RF 5 score on validate: {tf_rf5.score(tf_stem5_bow_val, y_stem_validate)}')\n",
    "print(f'TF/IDF RF 6 score on validate: {tf_rf6.score(tf_lem5_bow_val, y_lem_validate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About 20% dropoff in accuracy on validate. Count Vectorizers performing slightly better than TF/IDF."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
