{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import requests\n",
    "\n",
    "from acquire import scrape_github_data\n",
    "from prepare import words\n",
    "\n",
    "from env import github_token, github_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Imports for modeling... and stuff\n",
    "\n",
    "import pandas as pd\n",
    "from prepare import basic_clean, tokenize, stem, lemmatize, remove_stopwords, prep_article_data, words\n",
    "from acquire import scrape_github_data\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 250)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Decision Tree and Random Forest ;D\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run scraping function\n",
    "# data = scrape_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             500 non-null    object\n",
      " 1   language         470 non-null    object\n",
      " 2   readme_contents  500 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Turn scraped data into raw df\n",
    "# df = pd.DataFrame(data)\n",
    "df = pd.read_json('data.json')\n",
    "\n",
    "\n",
    "\n",
    "#Check returned df \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   repo                      500 non-null    object\n",
      " 1   language                  500 non-null    object\n",
      " 2   readme                    500 non-null    object\n",
      " 3   clean                     500 non-null    object\n",
      " 4   stemmed                   500 non-null    object\n",
      " 5   lemmatized                500 non-null    object\n",
      " 6   contains_python_keywords  500 non-null    int64 \n",
      " 7   contains_cpp_keywords     500 non-null    int64 \n",
      " 8   contains_js_keywords      500 non-null    int64 \n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 35.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = words(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other         277\n",
       "Python        104\n",
       "JavaScript     78\n",
       "C++            41\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 1) (120, 1) (100, 1)\n",
      "(280, 1) (120, 1) (100, 1)\n",
      "(280, 1) (120, 1) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Make copies of df with prepared columns and target\n",
    "clean_df = df.copy()[['language', 'clean']]\n",
    "stem_df = df.copy()[['language', 'stemmed']]\n",
    "lem_df = df.copy()[['language', 'lemmatized']]\n",
    "\n",
    "\n",
    "# Get splits for each of the above dfs and isolate target\n",
    "X_clean = clean_df[['clean']]\n",
    "y_clean = clean_df.language\n",
    "\n",
    "X_clean_train, X_clean_test, y_clean_train, y_clean_test = train_test_split(X_clean, y_clean, test_size=.2, random_state=302)\n",
    "X_clean_train, X_clean_validate, y_clean_train, y_clean_validate  = train_test_split(X_clean_train, y_clean_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_clean_train.shape, X_clean_validate.shape, X_clean_test.shape)\n",
    "\n",
    "X_stem = stem_df[['stemmed']]\n",
    "y_stem = stem_df.language\n",
    "\n",
    "X_stem_train, X_stem_test, y_stem_train, y_stem_test = train_test_split(X_stem, y_stem, test_size=.2, random_state=302)\n",
    "X_stem_train, X_stem_validate, y_stem_train, y_stem_validate  = train_test_split(X_stem_train, y_stem_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_stem_train.shape, X_stem_validate.shape, X_stem_test.shape)\n",
    "\n",
    "X_lem = lem_df[['lemmatized']]\n",
    "y_lem = lem_df.language\n",
    "\n",
    "X_lem_train, X_lem_test, y_lem_train, y_lem_test = train_test_split(X_lem, y_lem, test_size=.2, random_state=302)\n",
    "X_lem_train, X_lem_validate, y_lem_train, y_lem_validate  = train_test_split(X_lem_train, y_lem_train, test_size=.3, random_state=302)\n",
    "\n",
    "print(X_lem_train.shape, X_lem_validate.shape, X_lem_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 1 score: 0.825\n",
      "TF IDF tree 1 score: 0.8464285714285714\n"
     ]
    }
   ],
   "source": [
    "# \"Clean\" models\n",
    "cv_clean = CountVectorizer()\n",
    "tfidf_clean = TfidfVectorizer()\n",
    "\n",
    "cv_clean_bow = cv_clean.fit_transform(X_clean_train.clean)\n",
    "\n",
    "tf_clean_bow = tfidf_clean.fit_transform(X_clean_train.clean)\n",
    "\n",
    "\n",
    "# Make and fit decision tree object for cv_clean_bow\n",
    "cv_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree1.fit(cv_clean_bow, y_clean_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_clean_bow\n",
    "tf_tree1 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree1.fit(tf_clean_bow, y_clean_train)\n",
    "\n",
    "#Output tree scores\n",
    "print(f'CV tree 1 score: {cv_tree1.score(cv_clean_bow, y_clean_train)}')\n",
    "print(f'TF IDF tree 1 score: {tf_tree1.score(tf_clean_bow, y_clean_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 2 score: 0.8214285714285714\n",
      "TF IDF tree 2 score: 0.85\n"
     ]
    }
   ],
   "source": [
    "# \"Stemmed\" models\n",
    "cv_stem = CountVectorizer()\n",
    "tfidf_stem = TfidfVectorizer()\n",
    "\n",
    "# Bags\n",
    "cv_stem_bow = cv_stem.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem_bow = tfidf_stem.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit decision tree object for cv_stem_bow\n",
    "cv_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree2.fit(cv_stem_bow, y_stem_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_stem_bow\n",
    "tf_tree2 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree2.fit(tf_stem_bow, y_stem_train)\n",
    "\n",
    "\n",
    "#Get tree score\n",
    "print(f'CV tree 2 score: {cv_tree2.score(cv_stem_bow, y_stem_train)}')\n",
    "#Get tree score\n",
    "print(f'TF IDF tree 2 score: {tf_tree2.score(tf_stem_bow, y_stem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree score: 0.825\n",
      "TFIDF tree score: 0.8392857142857143\n"
     ]
    }
   ],
   "source": [
    "# \"Lemmatized\" models\n",
    "cv_lem = CountVectorizer()\n",
    "tfidf_lem = TfidfVectorizer()\n",
    "\n",
    "cv_lem_bow = cv_lem.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem_bow = tfidf_lem.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit decision tree object for cv_lem_bow\n",
    "cv_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree3.fit(cv_lem_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_lem_bow\n",
    "tf_tree3 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree3.fit(tf_lem_bow, y_lem_train)\n",
    "\n",
    "# Output tree scores\n",
    "print(f'CV tree score: {cv_tree3.score(cv_lem_bow, y_lem_train)}') \n",
    "print(f'TFIDF tree score: {tf_tree3.score(tf_lem_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CV_clean': 0.825,\n",
       " 'CV_stem': 0.8214285714285714,\n",
       " 'CV_lem': 0.825,\n",
       " 'TF/IDF_clean': 0.8464285714285714,\n",
       " 'TF/IDF_stem': 0.85,\n",
       " 'TF/IDF_lem': 0.8392857142857143}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_training_scores= {\n",
    "    'CV_clean': cv_tree1.score(cv_clean_bow, y_clean_train),\n",
    "    'CV_stem': cv_tree2.score(cv_stem_bow, y_stem_train),\n",
    "    'CV_lem': cv_tree3.score(cv_lem_bow, y_lem_train),\n",
    "    'TF/IDF_clean': tf_tree1.score(tf_clean_bow, y_clean_train),\n",
    "    'TF/IDF_stem': tf_tree2.score(tf_stem_bow, y_stem_train),\n",
    "    'TF/IDF_lem': tf_tree3.score(tf_lem_bow, y_lem_train)\n",
    "}\n",
    "\n",
    "dec_tree_training_scores\n",
    "#pd.DataFrame(dec_tree_training_scores, index=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways: Both vectorizers had scored the same on clean, stemmed, and lemmatized preparations of README text in previous evaluations. Current version of text preparations have models using TF/IDF vectorizers scoring higher on train split.\n",
    "\n",
    "### Update (16-May-2022): Data increased from 100 to 500 records. TF/IDF vectorizers still scoring higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF/IDF Decision Tree scores on validate split:\n",
      "----------------------------------------------\n",
      "Tree 1 [clean] score: 0.75\n",
      "Tree 2 [stemmed] score: 0.75\n",
      "Tree 3 [lemmatized] score: 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "print('TF/IDF Decision Tree scores on validate split:')\n",
    "print('----------------------------------------------')\n",
    "#Transform validate split with vectorizer\n",
    "tf_clean_bow_val = tfidf_clean.transform(X_clean_validate.clean)\n",
    "\n",
    "#Output tf_tree1 score on validate\n",
    "print(f'Tree 1 [clean] score: {tf_tree1.score(tf_clean_bow_val, y_clean_validate)}')\n",
    "\n",
    "#Transform validate split with vectorizer\n",
    "tf_stem_bow_val = tfidf_stem.transform(X_stem_validate.stemmed)\n",
    "\n",
    "#Output tf_tree2 score on validate\n",
    "print(f'Tree 2 [stemmed] score: {tf_tree2.score(tf_stem_bow_val, y_stem_validate)}')\n",
    "\n",
    "#Transform validate split with vectorizer\n",
    "tf_lem_bow_val = tfidf_lem.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "#Output tf_tree3 score on validate\n",
    "print(f'Tree 3 [lemmatized] score: {tf_tree3.score(tf_lem_bow_val, y_lem_validate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest models, 100 estimators, max depth 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RF 1 score: 0.8035714285714286\n",
      "TF IDF RF 1 score: 0.8428571428571429\n",
      "CV RF 2 score: 0.8285714285714286\n",
      "TF IDF RF 2 score: 0.8821428571428571\n",
      "CV RF 3 score: 0.8035714285714286\n",
      "TF IDF RF 3 score: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Make vectorizer objects\n",
    "cv_clean2 = CountVectorizer()\n",
    "tfidf_clean2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_clean2_bow = cv_clean2.fit_transform(X_clean_train.clean)\n",
    "tf_clean2_bow = tfidf_clean2.fit_transform(X_clean_train.clean)\n",
    "\n",
    "# Make and fit random forest object for cv_clean2_bow\n",
    "cv_rf1 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf1.fit(cv_clean2_bow, y_clean_train)\n",
    "\n",
    "#Make and fit random forest object for tf_clean2_bow\n",
    "tf_rf1 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf1.fit(tf_clean2_bow, y_clean_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 1 score: {cv_rf1.score(cv_clean2_bow, y_clean_train)}')\n",
    "print(f'TF IDF RF 1 score: {tf_rf1.score(tf_clean2_bow, y_clean_train)}')\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_stem2 = CountVectorizer()\n",
    "tfidf_stem2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_stem2_bow = cv_stem2.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem2_bow = tfidf_stem2.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit random object for cv_stem2_bow\n",
    "cv_rf2 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf2.fit(cv_stem2_bow, y_stem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_stem2_bow\n",
    "tf_rf2 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf2.fit(tf_stem2_bow, y_stem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 2 score: {cv_rf2.score(cv_stem2_bow, y_stem_train)}')\n",
    "print(f'TF IDF RF 2 score: {tf_rf2.score(tf_stem2_bow, y_stem_train)}')\n",
    "# Make vectorizer objects\n",
    "cv_lem2 = CountVectorizer()\n",
    "tfidf_lem2 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_lem2_bow = cv_lem2.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem2_bow = tfidf_lem2.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit decision tree object for cv_lem2_bow\n",
    "cv_rf3 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf3.fit(cv_lem2_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_lem2_bow\n",
    "tf_rf3 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf3.fit(tf_lem2_bow, y_lem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 3 score: {cv_rf3.score(cv_lem2_bow, y_lem_train)}')\n",
    "print(f'TF IDF RF 3 score: {tf_rf3.score(tf_lem2_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both vectorizers scoring the same on training split for all text preparations. All move on to validate.\n",
    "\n",
    "### Update (16-May-2022 11:15) TF/IDF vectorizers score higher than count vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF IDF RF 1 score on validate: 0.675\n",
      "TF IDF RF 2 score on validate: 0.7\n",
      "TF IDF RF 3 score on validate: 0.675\n"
     ]
    }
   ],
   "source": [
    "# Transform count vectorizers on validate\n",
    "#cv_clean2_bow_val = cv_clean2.transform(X_clean_validate.clean)\n",
    "#cv_stem2_bow_val = cv_stem2.transform(X_stem_validate.stemmed)\n",
    "#cv_lem2_bow_val = cv_lem2.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Output CV RF scores\n",
    "#print(f'CV RF 1 score on validate: {cv_rf1.score(cv_clean2_bow_val, y_clean_validate)}')\n",
    "#print(f'CV RF 2 score on validate: {cv_rf2.score(cv_stem2_bow_val, y_stem_validate)}')\n",
    "#print(f'CV RF 3 score on validate: {cv_rf3.score(cv_lem2_bow_val, y_lem_validate)}')\n",
    "\n",
    "# Transform TF IDF vectorizers on validate\n",
    "tf_clean2_bow_val = tfidf_clean2.transform(X_clean_validate.clean)\n",
    "tf_stem2_bow_val = tfidf_stem2.transform(X_stem_validate.stemmed)\n",
    "tf_lem2_bow_val = tfidf_lem2.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Output TF IDF RF scores\n",
    "print(f'TF IDF RF 1 score on validate: {tf_rf1.score(tf_clean2_bow_val, y_clean_validate)}')\n",
    "print(f'TF IDF RF 2 score on validate: {tf_rf2.score(tf_stem2_bow_val, y_stem_validate)}')\n",
    "print(f'TF IDF RF 3 score on validate: {tf_rf3.score(tf_lem2_bow_val, y_lem_validate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model using TF/IDF vectorizer on stemmed text performing at 70% accuracy on validate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make functions to speed up modeling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_cv_dt_score (text_data, target, max_depth, ngram_range=False, train_split=True):\n",
    "    #'''\n",
    "    #Takes in text_data, a target variable, an optional ngram range argument (min_n, max_n) for a Count Vectorizer object, and a max_depth kwarg for a Decision Tree,\n",
    "    #and returns a bag of words (bow), the Decision Tree object and its accuracy score on the train split.\n",
    "    #'''\n",
    "    #cv = CountVectorizer(ngram_range)\n",
    "    #bow = cv.fit_transform(text_data)\n",
    "    #tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    #tree.fit(bow, target)\n",
    "    \n",
    "    #if train_split:\n",
    "        #dt_score = tree.score(bow, target)\n",
    "        #return tree, bow, dt_score\n",
    "    #else:\n",
    "        #print('Use tree and bow returned from train split to get score on validate/test split.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_tfidf_dt_score (text_data, target, depth, train_split=True):\n",
    "    #'''\n",
    "    #Takes in text_data, a target variable, and a depth(max_depth) kwarg for a Decision Tree model,\n",
    "    #and returns the Decision Tree object and an accompanying accuracy score for the model.\n",
    "    #'''\n",
    "    #tfidf = TfidfVectorizer()\n",
    "    #bow = tfidf.fit_transform(text_data)\n",
    "    #tree = DecisionTreeClassifier(max_depth=depth)\n",
    "    #tree.fit(bow, target)\n",
    "\n",
    "    #if train_split:\n",
    "        #dt_score = tree.score(bow, target)\n",
    "    #else:\n",
    "        #raise Exception('')\n",
    "\n",
    "    #return tree, dt_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_cv_rf_score(text_data, target, depth, n_estimators, train_split=True):\n",
    "    #'''\n",
    "    #Takes in text data, a target variable, depth and n_estimators kwargs for a Random Forest model,\n",
    "    #and returns the Random Forest object and an accompanying accuracy score for the model.\n",
    "    #'''\n",
    "    #cv = CountVectorizer()\n",
    "    #bow = cv.fit_transform(text_data)\n",
    "    #rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=depth)\n",
    "    #rf.fit(bow, target)\n",
    "    \n",
    "    #if train_split:\n",
    "        #rf_score = rf.score(bow, target)\n",
    "    #else:\n",
    "        #bow = cv.transform(text_data)\n",
    "        #rf_score = rf.score(bow, target)\n",
    "    \n",
    "    #return rf, rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bags of bigrams -- Dec trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 4 score: 0.7214285714285714\n",
      "TF IDF tree 4 score: 0.725\n"
     ]
    }
   ],
   "source": [
    "# Bigrams\n",
    "\n",
    "# Make bags\n",
    "cv_clean3 = CountVectorizer(ngram_range=(2,2))\n",
    "tfidf_clean3 = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Fill bags with words\n",
    "cv_clean3_bow = cv_clean3.fit_transform(X_clean_train.clean)\n",
    "tf_clean3_bow = tfidf_clean3.fit_transform(X_clean_train.clean)\n",
    "\n",
    "\n",
    "# Make and fit decision tree object for cv_clean3_bow\n",
    "cv_tree4 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree4.fit(cv_clean3_bow, y_clean_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_clean_bow\n",
    "tf_tree4 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree4.fit(tf_clean3_bow, y_clean_train)\n",
    "\n",
    "#Output tree scores\n",
    "print(f'CV tree 4 score: {cv_tree4.score(cv_clean3_bow, y_clean_train)}')\n",
    "print(f'TF/IDF tree 4 score: {tf_tree4.score(tf_clean3_bow, y_clean_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 5 score: 0.725\n",
      "TF IDF tree 5 score: 0.7285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Make bags\n",
    "cv_stem3 = CountVectorizer(ngram_range=(2,2))\n",
    "tfidf_stem3 = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Fill bags with words\n",
    "cv_stem3_bow = cv_stem3.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem3_bow = tfidf_stem3.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "\n",
    "# Make and fit decision tree object for cv_stem3_bow\n",
    "cv_tree5 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree5.fit(cv_stem3_bow, y_stem_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_stem_bow\n",
    "tf_tree5 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree5.fit(tf_stem3_bow, y_stem_train)\n",
    "\n",
    "#Output tree scores\n",
    "print(f'CV tree 5 score: {cv_tree5.score(cv_stem3_bow, y_stem_train)}')\n",
    "print(f'TF/IDF tree 5 score: {tf_tree5.score(tf_stem3_bow, y_stem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV tree 6 score: 0.7214285714285714\n",
      "TF IDF tree 6 score: 0.725\n"
     ]
    }
   ],
   "source": [
    "cv_lem3 = CountVectorizer(ngram_range=(2,2))\n",
    "tfidf_lem3 = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Fill bags with words\n",
    "cv_lem3_bow = cv_lem3.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem3_bow = tfidf_lem3.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "\n",
    "# Make and fit decision tree object for cv_lem3_bow\n",
    "cv_tree6 = DecisionTreeClassifier(max_depth=5)\n",
    "cv_tree6.fit(cv_lem3_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision tree object for tf_lem_bow\n",
    "tf_tree6 = DecisionTreeClassifier(max_depth=5)\n",
    "tf_tree6.fit(tf_lem3_bow, y_lem_train)\n",
    "\n",
    "#Output tree scores\n",
    "print(f'CV tree 6 score: {cv_tree6.score(cv_lem3_bow, y_lem_train)}')\n",
    "print(f'TF/IDF tree 6 score: {tf_tree6.score(tf_lem3_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF/IDF [Bigram bags] Decision Tree scores on validate split:\n",
      "------------------------------------------------------------\n",
      "Tree 4 [clean] score: 0.7666666666666667\n",
      "Tree 2 [stemmed] score: 0.7583333333333333\n",
      "Tree 3 [lemmatized] score: 0.7583333333333333\n"
     ]
    }
   ],
   "source": [
    "print('TF/IDF [Bigram bags] Decision Tree scores on validate split:')\n",
    "print('------------------------------------------------------------')\n",
    "#Transform validate split with vectorizer\n",
    "tf_clean3_bow_val = tfidf_clean3.transform(X_clean_validate.clean)\n",
    "\n",
    "#Output tf_tree1 score on validate\n",
    "print(f'Tree 4 [clean] score: {tf_tree4.score(tf_clean3_bow_val, y_clean_validate)}')\n",
    "\n",
    "#Transform validate split with vectorizer\n",
    "tf_stem3_bow_val = tfidf_stem3.transform(X_stem_validate.stemmed)\n",
    "\n",
    "#Output tf_tree2 score on validate\n",
    "print(f'Tree 2 [stemmed] score: {tf_tree5.score(tf_stem3_bow_val, y_stem_validate)}')\n",
    "\n",
    "#Transform validate split with vectorizer\n",
    "tf_lem3_bow_val = tfidf_lem3.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "#Output tf_tree3 score on validate\n",
    "print(f'Tree 3 [lemmatized] score: {tf_tree6.score(tf_lem3_bow_val, y_lem_validate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RF 4 score: 0.5785714285714286\n",
      "TF IDF RF 4 score: 0.5892857142857143\n",
      "CV RF 2 score: 0.8321428571428572\n",
      "TF IDF RF 2 score: 0.8821428571428571\n",
      "CV RF 3 score: 0.7964285714285714\n",
      "TF IDF RF 3 score: 0.8464285714285714\n"
     ]
    }
   ],
   "source": [
    "# Make vectorizer objects\n",
    "cv_clean4 = CountVectorizer(ngram_range=(2,2))\n",
    "tfidf_clean4 = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_clean4_bow = cv_clean4.fit_transform(X_clean_train.clean)\n",
    "tf_clean4_bow = tfidf_clean4.fit_transform(X_clean_train.clean)\n",
    "\n",
    "# Make and fit random forest object for cv_clean4_bow\n",
    "cv_rf4 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf4.fit(cv_clean4_bow, y_clean_train)\n",
    "\n",
    "#Make and fit random forest object for tf_clean4_bow\n",
    "tf_rf4 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf4.fit(tf_clean4_bow, y_clean_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 4 score: {cv_rf4.score(cv_clean4_bow, y_clean_train)}')\n",
    "print(f'TF IDF RF 4 score: {tf_rf4.score(tf_clean4_bow, y_clean_train)}')\n",
    "\n",
    "# Make vectorizer objects\n",
    "cv_stem4 = CountVectorizer()\n",
    "tfidf_stem4 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_stem4_bow = cv_stem4.fit_transform(X_stem_train.stemmed)\n",
    "tf_stem4_bow = tfidf_stem4.fit_transform(X_stem_train.stemmed)\n",
    "\n",
    "# Make and fit random object for cv_stem4_bow\n",
    "cv_rf5 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf5.fit(cv_stem4_bow, y_stem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_stem4_bow\n",
    "tf_rf5 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf5.fit(tf_stem4_bow, y_stem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 2 score: {cv_rf5.score(cv_stem4_bow, y_stem_train)}')\n",
    "print(f'TF IDF RF 2 score: {tf_rf5.score(tf_stem4_bow, y_stem_train)}')\n",
    "# Make vectorizer objects\n",
    "cv_lem4 = CountVectorizer()\n",
    "tfidf_lem4 = TfidfVectorizer()\n",
    "\n",
    "#Fit vectorizer objects\n",
    "cv_lem4_bow = cv_lem4.fit_transform(X_lem_train.lemmatized)\n",
    "tf_lem4_bow = tfidf_lem4.fit_transform(X_lem_train.lemmatized)\n",
    "\n",
    "# Make and fit decision tree object for cv_lem4_bow\n",
    "cv_rf6 = RandomForestClassifier(n_estimators= 100, max_depth=15)\n",
    "cv_rf6.fit(cv_lem4_bow, y_lem_train)\n",
    "\n",
    "#Make and fit decision rf object for tf_lem4_bow\n",
    "tf_rf6 = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "tf_rf6.fit(tf_lem4_bow, y_lem_train)\n",
    "\n",
    "#Output rf scores\n",
    "print(f'CV RF 3 score: {cv_rf6.score(cv_lem4_bow, y_lem_train)}')\n",
    "print(f'TF IDF RF 3 score: {tf_rf6.score(tf_lem4_bow, y_lem_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF/IDF vectorizers outperform count vectorizers overall. RFs on stemmed bigrams scoring highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RF 5 score on validate: 0.675\n",
      "CV RF 6 score on validate: 0.6666666666666666\n",
      "TF/IDF RF 5 score on validate: 0.675\n",
      "TF/IDF RF 6 score on validate: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Transform count vectorizers on validate\n",
    "cv_stem4_bow_val = cv_stem4.transform(X_stem_validate.stemmed)\n",
    "cv_lem4_bow_val = cv_lem4.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "# Transform TF/IDF vectorizers on validate\n",
    "tf_stem4_bow_val = tfidf_stem4.transform(X_stem_validate.stemmed)\n",
    "tf_lem4_bow_val = tfidf_lem4.transform(X_lem_validate.lemmatized)\n",
    "\n",
    "#Output CV RF 5 & 6 scores on validate\n",
    "print(f'CV RF 5 score on validate: {cv_rf5.score(cv_stem4_bow_val, y_stem_validate)}')\n",
    "print(f'CV RF 6 score on validate: {cv_rf6.score(cv_lem4_bow_val, y_lem_validate)}')\n",
    "\n",
    "# Output TF/IDF RF 5 & 6 scores on validate\n",
    "print(f'TF/IDF RF 5 score on validate: {tf_rf5.score(tf_stem4_bow_val, y_stem_validate)}')\n",
    "print(f'TF/IDF RF 6 score on validate: {tf_rf6.score(tf_lem4_bow_val, y_lem_validate)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
