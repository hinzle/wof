{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "import prepare as prep\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(df.actual, df.prediction, labels = ('no coffee', 'coffee'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.crosstab(df.actual, df.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![confusion matrix](https://miro.medium.com/max/1400/1*fxiTNIgOyvAombPJx5KGeA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracy doesn't tell the whole story\n",
    "- baseline model predicts the most common class (not necessarily the postive class)\n",
    "- \\+ / - are somewhat arbitrary, but generally a postive prediction means taking action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![precision vs. recall](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/660px-Precisionrecall.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - percentage of positive predictions that are correct.\n",
    "> - helps eliminate FP\n",
    "> - whoa! there FN\n",
    "\n",
    "$$\\frac{\\text{TP}}{\\text{TP + FP}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - number of times the prediction was correct divided by the total number of observations\n",
    "> - helps TP and TN\n",
    "\n",
    "$$\\frac{\\text{TP + TN}}{\\text{TP + TN + FP + FN}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - a.k.a. - sensitivity\n",
    "> - percentage of positive cases that were accurately predicted\n",
    "> - helps eliminate FN\n",
    "> - whoa! there FP\n",
    "\n",
    "$$\\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusing more matrix's\n",
    "<table class=\"wikitable\" align=\"center\" style=\"border:none; background:gray; text-align:center;color:black;\">\n",
    "<tbody><tr>\n",
    "<td style=\"border:none;\" rowspan=\"2\">\n",
    "</td>\n",
    "<td style=\"border:none;\">\n",
    "</td>\n",
    "<td style=\"background:#bbeeee;\" colspan=\"2\"><b>Predicted condition</b>\n",
    "</td>\n",
    "<td style=\"border:none; text-align:right;\" colspan=\"2\"><sup>Sources: </sup><sup id=\"cite_ref-5\" class=\"reference\"><a href=\"#cite_note-5\">[5]</a></sup><sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">[6]</a></sup><sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\">[7]</a></sup><sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\">[8]</a></sup><sup id=\"cite_ref-9\" class=\"reference\"><a href=\"#cite_note-9\">[9]</a></sup><sup id=\"cite_ref-10\" class=\"reference\"><a href=\"#cite_note-10\">[10]</a></sup><sup id=\"cite_ref-11\" class=\"reference\"><a href=\"#cite_note-11\">[11]</a></sup><sup id=\"cite_ref-12\" class=\"reference\"><a href=\"#cite_note-12\">[12]</a></sup> <sup><style data-mw-deduplicate=\"TemplateStyles:r1063604349\">.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}</style><div class=\"navbar plainlinks hlist\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Diagnostic_testing_diagram\" title=\"Template:Diagnostic testing diagram\"><span title=\"View this template\">view</span></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Diagnostic_testing_diagram\" title=\"Template talk:Diagnostic testing diagram\"><span title=\"Discuss this template\">talk</span></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"https://en.wikipedia.org/w/index.php?title=Template:Diagnostic_testing_diagram&amp;action=edit\"><span title=\"Edit this template\">edit</span></a></li></ul></div></sup>\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background:#eeeeee;\"><a href=\"/wiki/Statistical_population\" title=\"Statistical population\">Total population</a> <br><span style=\"white-space:nowrap;\">= P + N</span>\n",
    "</td>\n",
    "<td style=\"background:#ccffff;\"><b>Positive (PP)</b>\n",
    "</td>\n",
    "<td style=\"background:#aadddd;\"><b>Negative (PN)</b>\n",
    "</td>\n",
    "<td style=\"border-left:double silver;\"><a href=\"/wiki/Youden%27s_J_statistic\" title=\"Youden's J statistic\">Informedness</a>, <span style=\"font-size:85%;\">bookmaker informedness (BM)</span> <br><span style=\"white-space:nowrap;\">= TPR + TNR − 1</span>\n",
    "</td>\n",
    "<td><a href=\"/wiki/Prevalence_threshold\" class=\"mw-redirect\" title=\"Prevalence threshold\">Prevalence threshold</a> (PT) <br><span style=\"white-space:nowrap;\">= <style data-mw-deduplicate=\"TemplateStyles:r1050945101\">.mw-parser-output .sfrac{white-space:nowrap}.mw-parser-output .sfrac.tion,.mw-parser-output .sfrac .tion{display:inline-block;vertical-align:-0.5em;font-size:85%;text-align:center}.mw-parser-output .sfrac .num,.mw-parser-output .sfrac .den{display:block;line-height:1em;margin:0 0.1em}.mw-parser-output .sfrac .den{border-top:1px solid}.mw-parser-output .sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}</style><span role=\"math\" class=\"sfrac tion\"><span class=\"num\"><span class=\"nowrap\">√<span style=\"border-top:1px solid; padding:0 0.1em;\">TPR × FPR</span></span> − FPR</span><span class=\"sr-only\">/</span><span class=\"den\">TPR − FPR</span></span></span>\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td rowspan=\"2\" class=\"nowrap unsortable\" style=\"line-height:99%;vertical-align:middle;padding:.4em .4em .2em;background-position:50% .4em !important;min-width:0.875em;max-width:0.875em;width:0.875em;overflow:hidden;background:#eeeebb;\"><div style=\"-webkit-writing-mode: vertical-rl; -o-writing-mode: vertical-rl; -ms-writing-mode: tb-rl;writing-mode: tb-rl; writing-mode: vertical-rl; layout-flow: vertical-ideographic;display: inline-block; -ms-transform: rotate(180deg); -webkit-transform: rotate(180deg); transform: rotate(180deg);;-ms-transform: none ;padding-left:1px;text-align:center;\"><b>Actual condition</b></div>\n",
    "</td>\n",
    "<td style=\"background:#ffffcc;\"><b>Positive (P)</b>\n",
    "</td>\n",
    "<td style=\"background:#ccffcc;\"><b><a href=\"/wiki/True_positive\" class=\"mw-redirect\" title=\"True positive\">True positive</a> (TP), <br><span style=\"font-size:85%;\">hit</span></b>\n",
    "</td>\n",
    "<td style=\"background:#ffdddd;\"><b><a href=\"/wiki/False_negative\" class=\"mw-redirect\" title=\"False negative\">False negative</a> (FN), <br><span style=\"font-size:85%;\"><a href=\"/wiki/Type_II_error\" class=\"mw-redirect\" title=\"Type II error\">type&nbsp;II&nbsp;error</a>, miss, <br>underestimation</span></b>\n",
    "</td>\n",
    "<td style=\"background:#eeffee;\"><a href=\"/wiki/True_positive_rate\" class=\"mw-redirect\" title=\"True positive rate\">True positive rate</a> (TPR), <a href=\"/wiki/Recall_(information_retrieval)\" class=\"mw-redirect\" title=\"Recall (information retrieval)\">recall</a>, <a href=\"/wiki/Sensitivity_(tests)\" class=\"mw-redirect\" title=\"Sensitivity (tests)\">sensitivity</a> (SEN), <span style=\"font-size:85%;\">probability&nbsp;of&nbsp;detection, hit&nbsp;rate, <a href=\"/wiki/Statistical_power\" class=\"mw-redirect\" title=\"Statistical power\">power</a></span> <br><span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">TP</span><span class=\"sr-only\">/</span><span class=\"den\">P</span></span></span> <span style=\"white-space:nowrap;\">= 1 − FNR</span>\n",
    "</td>\n",
    "<td style=\"background:#ffeeee;\"><a href=\"/wiki/False_negative_rate\" class=\"mw-redirect\" title=\"False negative rate\">False negative rate</a> (FNR), <br><span style=\"font-size:85%;\">miss&nbsp;rate</span> <br><span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">FN</span><span class=\"sr-only\">/</span><span class=\"den\">P</span></span></span> <span style=\"white-space:nowrap;\">= 1 − TPR</span>\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background:#ddddaa;\"><b>Negative (N)</b>\n",
    "</td>\n",
    "<td style=\"background:#ffcccc;\"><b><a href=\"/wiki/False_positive\" class=\"mw-redirect\" title=\"False positive\">False positive</a> (FP), <br><span style=\"font-size:85%;\"><a href=\"/wiki/Type_I_error\" class=\"mw-redirect\" title=\"Type I error\">type&nbsp;I&nbsp;error</a>, false alarm, <br>overestimation</span></b>\n",
    "</td>\n",
    "<td style=\"background:#bbeebb;\"><b><a href=\"/wiki/True_negative\" class=\"mw-redirect\" title=\"True negative\">True negative</a> (TN), <br><span style=\"font-size:85%;\">correct rejection</span></b>\n",
    "</td>\n",
    "<td style=\"background:#eedddd;\"><a href=\"/wiki/False_positive_rate\" title=\"False positive rate\">False positive rate</a> (FPR), <br><span style=\"font-size:85%;\">probability&nbsp;of&nbsp;false&nbsp;alarm, <a href=\"/wiki/Evaluation_measures_(information_retrieval)#Fall-out\" title=\"Evaluation measures (information retrieval)\"><span class=\"nowrap\">fall-out</span></a></span> <br><span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">FP</span><span class=\"sr-only\">/</span><span class=\"den\">N</span></span></span> <span style=\"white-space:nowrap;\">= 1 − TNR</span>\n",
    "</td>\n",
    "<td style=\"background:#ddeedd;\"><a href=\"/wiki/True_negative_rate\" class=\"mw-redirect\" title=\"True negative rate\">True negative rate</a> (TNR), <br><span style=\"font-size:85%;\"><a href=\"/wiki/Specificity_(tests)\" class=\"mw-redirect\" title=\"Specificity (tests)\">specificity</a> (SPC), selectivity</span> <br><span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">TN</span><span class=\"sr-only\">/</span><span class=\"den\">N</span></span></span> <span style=\"white-space:nowrap;\">= 1 − FPR</span>\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"border:none;\" rowspan=\"3\">\n",
    "</td>\n",
    "<td style=\"border-top:double silver; border-right:double silver;\"><a href=\"/wiki/Prevalence\" title=\"Prevalence\">Prevalence</a> <br><span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">P</span><span class=\"sr-only\">/</span><span class=\"den\">P + N</span></span></span>\n",
    "</td>\n",
    "<td style=\"background:#eeffee;\"><span class=\"nowrap\"><a href=\"/wiki/Positive_predictive_value\" class=\"mw-redirect\" title=\"Positive predictive value\">Positive predictive value</a> (PPV),</span> <span style=\"font-size:85%;\"><a href=\"/wiki/Precision_(information_retrieval)\" class=\"mw-redirect\" title=\"Precision (information retrieval)\">precision</a></span> <br><span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">TP</span><span class=\"sr-only\">/</span><span class=\"den\">PP</span></span></span> <span style=\"white-space:nowrap;\">= 1 − FDR</span>\n",
    "</td>\n",
    "<td style=\"background:#ffeeee;border-right:double silver;\"><a href=\"/wiki/False_omission_rate\" class=\"mw-redirect\" title=\"False omission rate\">False omission rate</a> (FOR) <br><span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">FN</span><span class=\"sr-only\">/</span><span class=\"den\">PN</span></span></span> <span style=\"white-space:nowrap;\">= 1 − NPV</span>\n",
    "</td>\n",
    "<td style=\"background:#eeeeff;\"><a href=\"/wiki/Positive_likelihood_ratio\" class=\"mw-redirect\" title=\"Positive likelihood ratio\">Positive likelihood ratio</a> (LR+) <br><span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">TPR</span><span class=\"sr-only\">/</span><span class=\"den\">FPR</span></span></span>\n",
    "</td>\n",
    "<td style=\"background:#eeeeff;\"><a href=\"/wiki/Negative_likelihood_ratio\" class=\"mw-redirect\" title=\"Negative likelihood ratio\">Negative likelihood ratio</a> (LR−) <br><span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">FNR</span><span class=\"sr-only\">/</span><span class=\"den\">TNR</span></span></span>\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"border-right:double silver;\"><a href=\"/wiki/Accuracy_and_precision#In_binary_classification\" title=\"Accuracy and precision\">Accuracy</a> (ACC) <span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">TP + TN</span><span class=\"sr-only\">/</span><span class=\"den\">P + N</span></span></span>\n",
    "</td>\n",
    "<td style=\"background:#eedddd;\"><a href=\"/wiki/False_discovery_rate\" title=\"False discovery rate\">False discovery rate</a> (FDR) <br><span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">FP</span><span class=\"sr-only\">/</span><span class=\"den\">PP</span></span></span> <span style=\"white-space:nowrap;\">= 1 − PPV</span>\n",
    "</td>\n",
    "<td style=\"background:#ddeedd;\"><a href=\"/wiki/Negative_predictive_value\" class=\"mw-redirect\" title=\"Negative predictive value\">Negative predictive value</a> (NPV) <span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">TN</span><span class=\"sr-only\">/</span><span class=\"den\">PN</span></span></span> <span style=\"white-space:nowrap;\">= 1 − FOR</span>\n",
    "</td>\n",
    "<td style=\"border-top:double silver;border-right:double silver;\"><a href=\"/wiki/Markedness\" title=\"Markedness\">Markedness</a> (MK), <span style=\"font-size:85%;\">deltaP (Δp)</span> <br><span style=\"white-space:nowrap;\">= PPV + NPV − 1</span>\n",
    "</td>\n",
    "<td style=\"background:#eeeeff;\"><a href=\"/wiki/Diagnostic_odds_ratio\" title=\"Diagnostic odds ratio\">Diagnostic <span class=\"nowrap\">odds ratio</span></a> (DOR) <span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">LR+</span><span class=\"sr-only\">/</span><span class=\"den\">LR−</span></span></span>\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td>Balanced accuracy (BA) <span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">TPR + TNR</span><span class=\"sr-only\">/</span><span class=\"den\">2</span></span></span>\n",
    "</td>\n",
    "<td style=\"border-top:double silver;\"><a href=\"/wiki/F1_score\" class=\"mw-redirect\" title=\"F1 score\">F<sub>1</sub> score</a> <br><span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">2 PPV × TPR</span><span class=\"sr-only\">/</span><span class=\"den\">PPV + TPR</span></span></span> <span>= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">2 TP</span><span class=\"sr-only\">/</span><span class=\"den\">2 TP + FP + FN</span></span></span>\n",
    "</td>\n",
    "<td style=\"border-top:double silver;\"><a href=\"/wiki/Fowlkes%E2%80%93Mallows_index\" title=\"Fowlkes–Mallows index\">Fowlkes–Mallows index</a> (FM) <span style=\"white-space:nowrap;\">= <span class=\"nowrap\">√<span style=\"border-top:1px solid; padding:0 0.1em;\">PPV×TPR</span></span></span>\n",
    "</td>\n",
    "<td style=\"border-top:double silver;\"><a href=\"/wiki/Matthews_correlation_coefficient\" class=\"mw-redirect\" title=\"Matthews correlation coefficient\">Matthews correlation coefficient</a> (MCC) <br>= <span class=\"nowrap\">√<span style=\"border-top:1px solid; padding:0 0.1em;\">TPR×TNR×PPV×NPV</span></span> − <span class=\"nowrap\">√<span style=\"border-top:1px solid; padding:0 0.1em;\">FNR×FPR×FOR×FDR</span></span>\n",
    "</td>\n",
    "<td style=\"border-top:double silver;\" colspan=\"2\">Threat score (TS), critical success index (CSI), <a href=\"/wiki/Jaccard_index#Jaccard_index_in_binary_classification_confusion_matrices\" title=\"Jaccard index\">Jaccard index</a> <span style=\"white-space:nowrap;\">= <link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1050945101\"><span role=\"math\" class=\"sfrac tion\"><span class=\"num\">TP</span><span class=\"sr-only\">/</span><span class=\"den\">TP + FN + FP</span></span></span>\n",
    "</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - CatDog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the following confusion matrix, evaluate (by hand) the model's performance.\n",
    "\n",
    "|               | pred dog   | pred cat   |\n",
    "|:------------  |-----------:|-----------:|\n",
    "| actual dog    |         46 |         7  |\n",
    "| actual cat    |         13 |         34 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of this problem, what is a false positive?\n",
    "- predicting dog when the actual animal is a cat\n",
    "- there are 13 false positives in this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of this problem, what is a false negative?\n",
    "- predicting not dog (cat) when the actual animal is a dog\n",
    "- there are 7 false negatives in this model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you describe this model?\n",
    "- accuracy = 46+34/(46+34+13+7) = 80%\n",
    "- recall = 46/(46+7) = 87%\n",
    "- precision = 46/(46+13) = 78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.8679245283018868, 0.7796610169491526)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=(46+34)/(46+34+13+7)\n",
    "rec=46/(46+7)\n",
    "pre=46/(46+13)\n",
    "acc, rec, pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Cody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defective Cody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cody=pd.read_csv('c3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   actual  200 non-null    object\n",
      " 1   model1  200 non-null    object\n",
      " 2   model2  200 non-null    object\n",
      " 3   model3  200 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "cody.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual     model1  model2     model3\n",
       "0  No Defect  No Defect  Defect  No Defect\n",
       "1  No Defect  No Defect  Defect     Defect\n",
       "2  No Defect  No Defect  Defect  No Defect\n",
       "3  No Defect     Defect  Defect     Defect\n",
       "4  No Defect  No Defect  Defect  No Defect"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cody.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=cody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which evaluation metric would be appropriate here?\n",
    "- recall, eliminate a defective Cody labelled happy (FP)\n",
    "---\n",
    "- $TP:$ defective Cody\n",
    "- $TN:$ happy Cody\n",
    "- $FP:$ defective Cody labelled happy\n",
    "- $FN:$ happy Cody labelled defective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual     model1     model2     model3\n",
       "13   Defect  No Defect     Defect     Defect\n",
       "30   Defect     Defect  No Defect     Defect\n",
       "65   Defect     Defect     Defect     Defect\n",
       "70   Defect     Defect     Defect     Defect\n",
       "74   Defect  No Defect  No Defect     Defect\n",
       "87   Defect  No Defect     Defect     Defect\n",
       "118  Defect  No Defect     Defect  No Defect\n",
       "135  Defect     Defect  No Defect     Defect\n",
       "140  Defect  No Defect     Defect     Defect\n",
       "147  Defect     Defect  No Defect     Defect\n",
       "163  Defect     Defect     Defect     Defect\n",
       "171  Defect  No Defect     Defect     Defect\n",
       "176  Defect  No Defect     Defect     Defect\n",
       "186  Defect  No Defect  No Defect  No Defect\n",
       "194  Defect     Defect  No Defect     Defect\n",
       "196  Defect     Defect  No Defect  No Defect"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_def=df[df.actual=='Defect']\n",
    "act_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp1 = (act_def.actual==act_def.model1).sum()\n",
    "fn1 = (act_def.actual != act_def.model1).sum()\n",
    "recall1=tp1/(tp1+fn1)\n",
    "recall1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp2 = (act_def.actual==act_def.model2).sum()\n",
    "fn2 = (act_def.actual != act_def.model2).sum()\n",
    "recall2=tp2/(tp2+fn2)\n",
    "recall2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp3 = (act_def.actual==act_def.model3).sum()\n",
    "fn3 = (act_def.actual != act_def.model3).sum()\n",
    "recall3=tp3/(tp3+fn3)\n",
    "recall3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model would be the best fit for this use case?\n",
    "- model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad News Cody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which evaluation metric would be appropriate here?\n",
    "- precision, eliminate a happy Cody going to HI (FN)\n",
    "---\n",
    "- $TP:$ defective Cody goes to HI\n",
    "- $TN:$ happy Cody stay's home\n",
    "- $FP:$ defective Cody stay's home\n",
    "- $FN:$ happy Cody goes to HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   actual  184 non-null    object\n",
      " 1   model1  184 non-null    object\n",
      " 2   model2  184 non-null    object\n",
      " 3   model3  184 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "act_not=df[df.actual=='No Defect']\n",
    "act_not.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp1 = (act_def.actual==act_def.model1).sum()\n",
    "fp1 = (act_not.actual != act_not.model1).sum()\n",
    "precision1=tp1/(tp1+fp1)\n",
    "precision1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp2 = (act_def.actual==act_def.model2).sum()\n",
    "fp2 = (act_not.actual != act_not.model2).sum()\n",
    "precision2=tp2/(tp2+fp2)\n",
    "precision2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13131313131313133"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp3 = (act_def.actual==act_def.model3).sum()\n",
    "fp3 = (act_not.actual != act_not.model3).sum()\n",
    "precision3=tp3/(tp3+fp3)\n",
    "precision3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model would be the best fit for this use case?\n",
    "- Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Gives You Paws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyp=pd.read_csv('gives_you_paws.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   actual  5000 non-null   object\n",
      " 1   model1  5000 non-null   object\n",
      " 2   model2  5000 non-null   object\n",
      " 3   model3  5000 non-null   object\n",
      " 4   model4  5000 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "gyp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4\n",
       "0    cat    cat    dog    cat    dog\n",
       "1    dog    dog    cat    cat    dog\n",
       "2    dog    cat    cat    cat    dog\n",
       "3    dog    dog    dog    cat    dog\n",
       "4    cat    cat    cat    dog    dog"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gyp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4 baseline\n",
       "0    cat    cat    dog    cat    dog      dog\n",
       "1    dog    dog    cat    cat    dog      dog\n",
       "2    dog    cat    cat    cat    dog      dog\n",
       "3    dog    dog    dog    cat    dog      dog\n",
       "4    cat    cat    cat    dog    dog      dog\n",
       "5    dog    dog    dog    dog    dog      dog"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gyp['baseline']='dog'\n",
    "gyp.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4 baseline\n",
       "0    cat    cat    dog    cat    dog      dog\n",
       "1    dog    dog    cat    cat    dog      dog\n",
       "2    dog    cat    cat    cat    dog      dog\n",
       "3    dog    dog    dog    cat    dog      dog\n",
       "4    cat    cat    cat    dog    dog      dog"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=gyp\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of accuracy, how do the various models compare to the baseline model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6508"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.baseline == df.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8074"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.model1 == df.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6304"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.model2 == df.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5096"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.model3 == df.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.model4 == df.actual).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are any of the models better than the baseline?\n",
    "- models 1 & 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team Dog:\n",
    "\n",
    "- $TP:$ dog picture\n",
    "- $TN:$ cat picture\n",
    "- $FP:$ cat pic in the dog house\n",
    "- $FN:$ dog pic in the litter box\n",
    "---\n",
    "- recall: eliminate FN, we don't want any dog pics in the litter box, first pass over the data train for sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4 baseline\n",
       "0    cat    cat    dog    cat    dog      dog\n",
       "1    dog    dog    cat    cat    dog      dog\n",
       "2    dog    cat    cat    cat    dog      dog\n",
       "3    dog    dog    dog    cat    dog      dog\n",
       "4    cat    cat    cat    dog    dog      dog"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4 baseline\n",
       "1    dog    dog    cat    cat    dog      dog\n",
       "2    dog    cat    cat    cat    dog      dog\n",
       "3    dog    dog    dog    cat    dog      dog\n",
       "5    dog    dog    dog    dog    dog      dog\n",
       "8    dog    dog    cat    dog    dog      dog"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog=df[df.actual=='dog']\n",
    "dog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpb=(dog.actual==dog.baseline).mean()\n",
    "fpb=(dog.actual!=dog.baseline).mean()\n",
    "recallb=tpb/(tpb+fpb)\n",
    "recallb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803318992009834"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp1=(dog.actual==dog.model1).mean()\n",
    "fp1=(dog.actual!=dog.model1).mean()\n",
    "recall1=tp1/(tp1+fp1)\n",
    "recall1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49078057775046097"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp2=(dog.actual==dog.model2).mean()\n",
    "fp2=(dog.actual!=dog.model2).mean()\n",
    "recall2=tp2/(tp2+fp2)\n",
    "recall2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5086047940995697"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp3=(dog.actual==dog.model3).mean()\n",
    "fp3=(dog.actual!=dog.model3).mean()\n",
    "recall3=tp3/(tp3+fp3)\n",
    "recall3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9557467732022127"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp4=(dog.actual==dog.model4).mean()\n",
    "fp4=(dog.actual!=dog.model4).mean()\n",
    "recall4=tp4/(tp4+fp4)\n",
    "recall4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase I: Which of these models would you recomend for?\n",
    "- model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   actual    5000 non-null   object\n",
      " 1   model1    5000 non-null   object\n",
      " 2   model2    5000 non-null   object\n",
      " 3   model3    5000 non-null   object\n",
      " 4   model4    5000 non-null   object\n",
      " 5   baseline  5000 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4 baseline\n",
       "0    cat    cat    dog    cat    dog      dog\n",
       "1    dog    dog    cat    cat    dog      dog\n",
       "2    dog    cat    cat    cat    dog      dog\n",
       "3    dog    dog    dog    cat    dog      dog\n",
       "4    cat    cat    cat    dog    dog      dog"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase II: Which of these models would you recomend?  \n",
    "- model 2\n",
    "---\n",
    "We have retrieved the dog pics (TP) with high sensitivity, meaning we did a good job picking out all the dog pics, but we also had some cat pics in the mix (FP). Next, we turn up the precision because we want to know for sure on this pass that what we are looking at is, in fact, a dog, and, unfortunately, we may lose some dog pics (FN) along the way to weeding out all the cats (TN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual      1.000000\n",
       "model1      0.890024\n",
       "model2      0.893177\n",
       "model3      0.659888\n",
       "model4      0.731249\n",
       "baseline    0.650800\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision=df.apply(lambda col:((col=='dog')&(col==df.actual)).sum()/(col=='dog').sum())\n",
    "precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team Cat:\n",
    "---\n",
    "Give team cat the same run as team dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual model1 model2 model3 model4 baseline\n",
       "0       cat    cat    dog    cat    dog      cat\n",
       "1       dog    dog    cat    cat    dog      cat\n",
       "2       dog    cat    cat    cat    dog      cat\n",
       "3       dog    dog    dog    cat    dog      cat\n",
       "4       cat    cat    cat    dog    dog      cat\n",
       "...     ...    ...    ...    ...    ...      ...\n",
       "4995    dog    dog    dog    dog    dog      cat\n",
       "4996    dog    dog    cat    cat    dog      cat\n",
       "4997    dog    cat    cat    dog    dog      cat\n",
       "4998    cat    cat    cat    cat    dog      cat\n",
       "4999    dog    dog    dog    dog    dog      cat\n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.baseline='cat'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase I: Which of these models would you recomend?\n",
    "- model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual      1.000000\n",
       "model1      0.815006\n",
       "model2      0.890607\n",
       "model3      0.511455\n",
       "model4      0.345361\n",
       "baseline    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_recall=df.apply(lambda c: ((c==df.actual)&(df.actual=='cat')).sum()/(df.actual=='cat').sum())\n",
    "cat_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase II: Which of these models would you recomend?\n",
    "- Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "actual:\n",
      "              cat     dog  accuracy  macro avg  weighted avg\n",
      "precision     1.0     1.0       1.0        1.0           1.0\n",
      "recall        1.0     1.0       1.0        1.0           1.0\n",
      "f1-score      1.0     1.0       1.0        1.0           1.0\n",
      "support    1746.0  3254.0       1.0     5000.0        5000.0\n",
      "\n",
      "model1:\n",
      "                   cat          dog  accuracy    macro avg  weighted avg\n",
      "precision     0.689772     0.890024    0.8074     0.789898      0.820096\n",
      "recall        0.815006     0.803319    0.8074     0.809162      0.807400\n",
      "f1-score      0.747178     0.844452    0.8074     0.795815      0.810484\n",
      "support    1746.000000  3254.000000    0.8074  5000.000000   5000.000000\n",
      "\n",
      "model2:\n",
      "                   cat          dog  accuracy    macro avg  weighted avg\n",
      "precision     0.484122     0.893177    0.6304     0.688649      0.750335\n",
      "recall        0.890607     0.490781    0.6304     0.690694      0.630400\n",
      "f1-score      0.627269     0.633479    0.6304     0.630374      0.631310\n",
      "support    1746.000000  3254.000000    0.6304  5000.000000   5000.000000\n",
      "\n",
      "model3:\n",
      "                   cat          dog  accuracy    macro avg  weighted avg\n",
      "precision     0.358347     0.659888    0.5096     0.509118      0.554590\n",
      "recall        0.511455     0.508605    0.5096     0.510030      0.509600\n",
      "f1-score      0.421425     0.574453    0.5096     0.497939      0.521016\n",
      "support    1746.000000  3254.000000    0.5096  5000.000000   5000.000000\n",
      "\n",
      "model4:\n",
      "                   cat          dog  accuracy    macro avg  weighted avg\n",
      "precision     0.807229     0.731249    0.7426     0.769239      0.757781\n",
      "recall        0.345361     0.955747    0.7426     0.650554      0.742600\n",
      "f1-score      0.483755     0.828560    0.7426     0.656157      0.708154\n",
      "support    1746.000000  3254.000000    0.7426  5000.000000   5000.000000\n",
      "\n",
      "baseline:\n",
      "                  cat     dog  accuracy   macro avg  weighted avg\n",
      "precision     0.34920     0.0    0.3492     0.17460      0.121941\n",
      "recall        1.00000     0.0    0.3492     0.50000      0.349200\n",
      "f1-score      0.51764     0.0    0.3492     0.25882      0.180760\n",
      "support    1746.00000  3254.0    0.3492  5000.00000   5000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f'''\\n{c}:\\n{pd.DataFrame(classification_report(df.actual,eval('df.'+c),output_dict=True))}''') for c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "actual:\n",
      "1.0\n",
      "\n",
      "model1:\n",
      "0.8074\n",
      "\n",
      "model2:\n",
      "0.6304\n",
      "\n",
      "model3:\n",
      "0.5096\n",
      "\n",
      "model4:\n",
      "0.7426\n",
      "\n",
      "baseline:\n",
      "0.3492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f'''\\n{c}:\\n{accuracy_score(df.actual,eval('df.'+c))}''') for c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.metrics.precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "actual:\n",
      "1.0\n",
      "\n",
      "model1:\n",
      "0.6897721764420747\n",
      "\n",
      "model2:\n",
      "0.4841220423412204\n",
      "\n",
      "model3:\n",
      "0.358346709470305\n",
      "\n",
      "model4:\n",
      "0.8072289156626506\n",
      "\n",
      "baseline:\n",
      "0.3492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f'''\\n{c}:\\n{precision_score(df.actual,eval('df.'+c),pos_label='cat')}''') for c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.metrics.recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "actual:\n",
      "1.0\n",
      "\n",
      "model1:\n",
      "0.8150057273768614\n",
      "\n",
      "model2:\n",
      "0.8906071019473081\n",
      "\n",
      "model3:\n",
      "0.5114547537227949\n",
      "\n",
      "model4:\n",
      "0.34536082474226804\n",
      "\n",
      "baseline:\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f'''\\n{c}:\\n{recall_score(df.actual,eval('df.'+c),pos_label='cat')}''') for c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.metrics.classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "actual:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       1.00      1.00      1.00      1746\n",
      "         dog       1.00      1.00      1.00      3254\n",
      "\n",
      "    accuracy                           1.00      5000\n",
      "   macro avg       1.00      1.00      1.00      5000\n",
      "weighted avg       1.00      1.00      1.00      5000\n",
      "\n",
      "\n",
      "model1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.69      0.82      0.75      1746\n",
      "         dog       0.89      0.80      0.84      3254\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.79      0.81      0.80      5000\n",
      "weighted avg       0.82      0.81      0.81      5000\n",
      "\n",
      "\n",
      "model2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.48      0.89      0.63      1746\n",
      "         dog       0.89      0.49      0.63      3254\n",
      "\n",
      "    accuracy                           0.63      5000\n",
      "   macro avg       0.69      0.69      0.63      5000\n",
      "weighted avg       0.75      0.63      0.63      5000\n",
      "\n",
      "\n",
      "model3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.36      0.51      0.42      1746\n",
      "         dog       0.66      0.51      0.57      3254\n",
      "\n",
      "    accuracy                           0.51      5000\n",
      "   macro avg       0.51      0.51      0.50      5000\n",
      "weighted avg       0.55      0.51      0.52      5000\n",
      "\n",
      "\n",
      "model4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.81      0.35      0.48      1746\n",
      "         dog       0.73      0.96      0.83      3254\n",
      "\n",
      "    accuracy                           0.74      5000\n",
      "   macro avg       0.77      0.65      0.66      5000\n",
      "weighted avg       0.76      0.74      0.71      5000\n",
      "\n",
      "\n",
      "baseline:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.35      1.00      0.52      1746\n",
      "         dog       0.00      0.00      0.00      3254\n",
      "\n",
      "    accuracy                           0.35      5000\n",
      "   macro avg       0.17      0.50      0.26      5000\n",
      "weighted avg       0.12      0.35      0.18      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f'''\\n{c}:\\n{classification_report(df.actual,eval('df.'+c))}''') for c in df.columns]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
