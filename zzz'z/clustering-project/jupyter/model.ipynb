{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (model.py, line 160)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/local/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3444\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/mk/w2hz4wxx7xn5hr_56wz536gh0000gn/T/ipykernel_8929/1109330505.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from utils.model import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/hinzlehome/codeup-data-science/clustering-project/utils/model.py\"\u001b[0;36m, line \u001b[0;32m160\u001b[0m\n\u001b[0;31m    X_validate,centroids=cluster(X_validate,'calculatedfinishedsquarefeet','taxvaluedollarcnt',2)\u001b[0m\n\u001b[0m                                                                                                 ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/hinzlehome/codeup-data-science/clustering-project/')\n",
    "\n",
    "from utils.imports import *\n",
    "from utils.wrangle import *\n",
    "from utils.model import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_validate, y_validate, X_test, y_test=sml_zillow(['logerror'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols=train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['calculatedfinishedsquarefeet','taxvaluedollarcnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia(X_train,cols,1,6)\n",
    "\n",
    "# kmeans object ; helps identify best k for cluster \n",
    "# \"inertia\" : sum of the squared distances from each point to it's assigned centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call cluster function to add 'cluster' col to df with each entries kmeans cluster\n",
    "X_train,centroids=cluster(X_train,'calculatedfinishedsquarefeet','taxvaluedollarcnt',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=X_train,x='calculatedfinishedsquarefeet',y='taxvaluedollarcnt',hue='cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish baseline to determine the validity of our various models. In this case median is used since outliers have not been addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses, y_train, pf=reg_zillow_train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_zillow_train(X_train,y_train):\n",
    "\n",
    "\ty_train['yhat_base_prop']=y_train.logerror.mean()\n",
    "\n",
    "\n",
    "\t# evaluate: rmse\n",
    "\tmse_baseline = mean_squared_error(y_train.logerror, y_train.yhat_base_prop)\n",
    "\n",
    "\tmodel = LinearRegression().fit(X_train[['cluster']],y_train['logerror'])\n",
    "\n",
    "\ty_train['yhat_prop_ols'] = model.predict(X_train[['cluster']])\n",
    "\n",
    "\tmse_ols = mean_squared_error(y_train.logerror, y_train.yhat_prop_ols)\n",
    "\n",
    "\tprint(\"MSE OLS sklearn: \",\"{:.2e}\".format(mse_ols)) \n",
    "\n",
    "\tif mse_ols-mse_baseline<0:\n",
    "\t\tprint(\"y_hat_ols superior\")\n",
    "\telse:\n",
    "\t\tprint(\"yhat_baseline superior\")\n",
    "\n",
    "\tlars = LassoLars(alpha=1.0)\n",
    "\n",
    "\t# create the model object\n",
    "\n",
    "\tlars.fit(X_train[['cluster']], y_train.logerror)\n",
    "\n",
    "\t# fit the model to our training data. We must specify the column in y_train, \n",
    "\t# since we have converted it to a dataframe from a series!\n",
    "\n",
    "\ty_train['yhat_prop_lars'] = lars.predict(X_train[['cluster']])\n",
    "\n",
    "\t# predict train\n",
    "\n",
    "\t# evaluate: rmse\n",
    "\tmse_lars_train = mean_squared_error(y_train.logerror, y_train.yhat_prop_lars)\n",
    "\n",
    "\n",
    "\tprint(\"MSE for Lasso + Lars\\nTraining/In-Sample: \",\"{:.2e}\".format(mse_lars_train))\n",
    "\n",
    "\tif mse_lars_train-mse_baseline<0:\n",
    "\t\tprint(\"y_hat_lars superior\")\n",
    "\telse:\n",
    "\t\tprint(\"yhat_baseline superior\")\n",
    "\n",
    "\n",
    "\t# create the model object\n",
    "\tglm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "\t# fit the model to our training data. We must specify the column in y_train, \n",
    "\t# since we have converted it to a dataframe from a series! \n",
    "\tglm.fit(X_train[['cluster']], y_train.logerror)\n",
    "\n",
    "\t# predict train\n",
    "\ty_train['yhat_prop_glm'] = glm.predict(X_train[['cluster']])\n",
    "\n",
    "\t# evaluate: mse\n",
    "\tmse_glm_train = mean_squared_error(y_train.logerror, y_train.yhat_prop_glm)\n",
    "\n",
    "\tprint(\"MSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \",\"{:.2e}\".format( mse_glm_train))\n",
    "\n",
    "\tif mse_glm_train-mse_baseline<0:\n",
    "\t\tprint(\"y_hat superior\")\n",
    "\telse:\n",
    "\t\tprint(\"yhat_baseline superior\")\n",
    "\n",
    "\t# make the polynomial features to get a new set of features\n",
    "\tpf = PolynomialFeatures(degree=2)\n",
    "\n",
    "\t# fit and transform X_train_scaled\n",
    "\tX_train_degree2 = pf.fit_transform(X_train[['cluster']])\n",
    "\n",
    "\t# create the model object\n",
    "\tlmp = LinearRegression(normalize=True)\n",
    "\n",
    "\t# fit the model to our training data. We must specify the column in y_train, \n",
    "\t# since we have converted it to a dataframe from a series! \n",
    "\tlmp.fit(X_train_degree2,y_train.logerror)\n",
    "\n",
    "\t# predict train\n",
    "\ty_train['yhat_prop_lmp'] = lmp.predict(X_train_degree2)\n",
    "\n",
    "\t# evaluate: rmse\n",
    "\tmse_lmp_train = mean_squared_error(y_train.logerror, y_train.yhat_prop_lmp)\n",
    "\n",
    "\tprint(\"MSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \",\"{:.2e}\".format( mse_lmp_train))\n",
    "\n",
    "\tif mse_glm_train-mse_baseline<0:\n",
    "\t\tprint(\"y_hat superior\")\n",
    "\telse:\n",
    "\t\tprint(\"yhat_baseline superior\")\n",
    "\t\t\n",
    "\tmses=pd.DataFrame([mse_baseline,\n",
    "\tmse_ols,\n",
    "\tmse_lars_train,\n",
    "\tmse_glm_train,\n",
    "\tmse_lmp_train],\n",
    "\tcolumns=['mse'],\n",
    "\tindex= ['mse_baseline',\n",
    "\t'mse_ols',\n",
    "\t'mse_lars_train',\n",
    "\t'mse_glm_train',\n",
    "\t'mse_lmp_train'])\n",
    "\tprint(mses)\n",
    "\tprint(y_train)\n",
    "\n",
    "\treturn mses, y_train, pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\tX_validate,centroids=cluster(X_validate,'calculatedfinishedsquarefeet','taxvaluedollarcnt',2)\n",
    "\n",
    "\t# transform X_validate_scaled \n",
    "\tX_validate_degree2 = pf.transform(X_validate[['cluster']])\n",
    "\n",
    "\n",
    "\ty_validate['yhat_val_base'] = y_validate.logerror.mean()\n",
    "\n",
    "\ty_validate['yhat_val_ols'] = model.predict(X_validate[['cluster']])\n",
    "\n",
    "\ty_validate['yhat_val_lars'] = lars.predict(X_validate[['cluster']])\n",
    "\n",
    "\ty_validate['yhat_val_glm'] = glm.predict(X_validate[['cluster']])\n",
    "\n",
    "\ty_validate['yhat_val_lmp'] = lmp.predict(X_validate_degree2)\n",
    "\n",
    "\n",
    "\n",
    "\tmse_base_val = mean_squared_error(y_validate.logerror, y_validate.yhat_val_base)\n",
    "\n",
    "\tmse_ols_val = mean_squared_error(y_validate.logerror, y_validate.yhat_val_ols)\n",
    "\n",
    "\tmse_lars_val = mean_squared_error(y_validate.logerror, y_validate.yhat_val_lars)\n",
    "\n",
    "\tmse_glm_val = mean_squared_error(y_validate.logerror, y_validate.yhat_val_glm)\n",
    "\n",
    "\tmse_lmp_val = mean_squared_error(y_validate.logerror, y_validate.yhat_val_lmp)\n",
    "\n",
    "\tmse_val=[mse_base_val,mse_ols_val,mse_lars_val,mse_glm_val,mse_lmp_val]\n",
    "\tmse_val=pd.DataFrame(mse_val,index=['mse_base_val','mse_ols_val','mse_lars_val','mse_glm_val','mse_lmp_val' ],columns=['mse'])\n",
    "\n",
    "\tprint(y_validate.mean())\n",
    "\tprint(mse_val)\n",
    "\n",
    "\treturn y_validate, mse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate, mse_val= reg_zillow_val(X_validate,y_validate,pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our median baseline is the most effective predictor in this case. The best model is the is Lasso Lars model. We will use this model for our test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,centroids=cluster(X_test,'calculatedfinishedsquarefeet','taxvaluedollarcnt',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_degree2 = pf.transform(X_test[['cluster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_test[['cluster']],y_test['logerror'])\n",
    "\n",
    "y_test['yhat_test_ols'] = model.predict(X_test[['cluster']])\n",
    "\n",
    "mse_ols = mean_squared_error(y_test.logerror, y_test.yhat_test_ols)\n",
    "\n",
    "print(\"MSE OLS sklearn: \",\"{:.2e}\".format(mse_ols)) \n",
    "\n",
    "y_test['test_baseline'] = y_test['logerror'].median()\n",
    "\n",
    "mse_test_baseline=mean_squared_error(y_test.logerror, y_test.test_baseline)\n",
    "\n",
    "if mse_ols-mse_test_baseline<0:\n",
    "\tprint(\"y_hat superior\")\n",
    "else:\n",
    "\tprint(\"yhat_baseline superior\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
